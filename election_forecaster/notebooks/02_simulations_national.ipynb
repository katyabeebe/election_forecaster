{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we run a monte carlo simulation using the provincial level win probabilities. \n",
    "\n",
    "National level:\n",
    "- mean expected vote share per party\n",
    "- probability of winning per party\n",
    "\n",
    "The results of this notebook are stored in `/results`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the provincial results\n",
    "\n",
    "directory = '/Users/kbeebe/Desktop/economist_forecasting/election_forecaster/election_forecaster/results/'\n",
    "\n",
    "filelist = [file for file in os.listdir(directory) if file.startswith('provincial')]\n",
    "for file in filelist:\n",
    "    exec(\"%s = pd.read_csv('%s')\" % (file.split('.')[0], os.path.join(directory,file)))\n",
    "\n",
    "# load dataland state electoral votes\n",
    "electoral_college_votes = pd.read_csv('/Users/kbeebe/Desktop/economist_forecasting/election_forecaster/raw_data/dataland_demographics.csv')[['province', 'electoral_college_votes']]\n",
    "ecv = np.array(electoral_college_votes.electoral_college_votes) # array for calculations later\n",
    "draws = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dates\n",
    "dates_sc_A = provincial_forecast_A.date.unique()\n",
    "dates_sc_B = provincial_forecast_B.date.unique()\n",
    "dates_sc_C = provincial_forecast_C.date.unique()\n",
    "dates_sc_D = provincial_forecast_D.date.unique()\n",
    "dates_sc_E = provincial_forecast_E.date.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean_vote_share(df_input, dates):\n",
    "\n",
    "    national_results = []\n",
    "    for date in dates:\n",
    "        df = df_input[(df_input['date']==date)]\n",
    "        sel_cols = df.columns.str.contains('mean_vote_share')\n",
    "        df = df[df.columns[sel_cols]]\n",
    "\n",
    "        # get the mean for each party over all provinces\n",
    "        mean_vote_cols = df.columns.str.contains('mean_vote_share')\n",
    "        column_means = df[df.columns[mean_vote_cols]].mean()\n",
    "\n",
    "        res_df = pd.DataFrame([column_means.values], columns=column_means.index)\n",
    "        res_df.insert(0, 'date', date)\n",
    "        national_results.append(res_df)\n",
    "\n",
    "    # concat\n",
    "    df_national_results = pd.concat(national_results)\n",
    "    return df_national_results\n",
    "\n",
    "def run_prob_simulation(df_input, dates):\n",
    "\n",
    "    national_results = []\n",
    "    for date in dates:\n",
    "        df = df_input[(df_input['date']==date)]\n",
    "        sel_cols = df.columns.str.contains('win_probability')\n",
    "        df = df[df.columns[sel_cols]]\n",
    "        # transform to cumulative so we know random dice draws falls in which party probability\n",
    "        df_cumsum = df.cumsum(axis = 1, skipna = True)\n",
    "    \n",
    "        # simulate random roll of the dice\n",
    "        simulated_values_array = np.random.rand(12,draws) # 12 states, n draws\n",
    "    \n",
    "        # Initialize an empty array to store next largest indices\n",
    "        next_largest_indices_array = np.empty_like(simulated_values_array)\n",
    "        \n",
    "        # Loop through each set of simulated values (each column in the matrix)\n",
    "        for i in range(simulated_values_array.shape[1]):\n",
    "            simulated_values = simulated_values_array[:, i]  # Get simulated values for the current simulation\n",
    "            \n",
    "            # Find the index of the next largest party for each state\n",
    "            next_largest_indices = np.argmax((df_cumsum.values >= simulated_values[:, np.newaxis]), axis=1)\n",
    "            \n",
    "            # Store the next largest indices in the corresponding position of the array\n",
    "            next_largest_indices_array[:, i] = next_largest_indices\n",
    "    \n",
    "        # Calculate the total electoral college votes won by each party in each simulation run\n",
    "        total_votes_party_index_0 = np.sum(np.where(next_largest_indices_array == 0, ecv[:, np.newaxis], 0), axis=0)\n",
    "        total_votes_party_index_1 = np.sum(np.where(next_largest_indices_array == 1, ecv[:, np.newaxis], 0), axis=0)\n",
    "        total_votes_party_index_2 = np.sum(np.where(next_largest_indices_array == 2, ecv[:, np.newaxis], 0), axis=0)\n",
    "        total_votes_party_index_3 = np.sum(np.where(next_largest_indices_array == 3, ecv[:, np.newaxis], 0), axis=0)\n",
    "        \n",
    "        # # Determine the winning party for each simulation run\n",
    "        winning_party_indices = np.argmax([total_votes_party_index_0, total_votes_party_index_1, total_votes_party_index_2, total_votes_party_index_3], axis=0)\n",
    "        \n",
    "        # Count the number of times each party wins\n",
    "        win_counts = np.bincount(winning_party_indices)\n",
    "        \n",
    "        # Calculate the total number of simulation runs\n",
    "        total_runs = len(winning_party_indices)\n",
    "        \n",
    "        # Calculate the probability of each party winning over all runs\n",
    "        win_probabilities = win_counts / total_runs\n",
    "        \n",
    "        # Ensure win_probabilities has probabilities for all parties\n",
    "        num_parties = 4  # Assuming there are 4 parties\n",
    "        if len(win_probabilities) < num_parties:\n",
    "            missing_parties = num_parties - len(win_probabilities)\n",
    "            win_probabilities = np.append(win_probabilities, [0] * missing_parties)\n",
    "    \n",
    "        win_prob_column_names = df.columns\n",
    "        res_df = pd.DataFrame([win_probabilities], columns=win_prob_column_names)\n",
    "        res_df.insert(0, 'date', date)\n",
    "        national_results.append(res_df)\n",
    "        \n",
    "    \n",
    "    # concat\n",
    "    df_national_results = pd.concat(national_results)\n",
    "    return df_national_results\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scenario A\n",
    "df_national_mean_vote_shares_A = calculate_mean_vote_share(provincial_forecast_A, dates_sc_A)\n",
    "df_national_win_probs_A = run_prob_simulation(provincial_forecast_A, dates_sc_A)\n",
    "df_national_results_A = df_national_mean_vote_shares_A.merge(df_national_win_probs_A, on='date')\n",
    "# save\n",
    "df_national_results_A.to_csv(\"../results/national_forecast_A.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scenario B\n",
    "df_national_mean_vote_shares_B = calculate_mean_vote_share(provincial_forecast_B, dates_sc_B)\n",
    "df_national_win_probs_B = run_prob_simulation(provincial_forecast_B, dates_sc_B)\n",
    "df_national_results_B = df_national_mean_vote_shares_B.merge(df_national_win_probs_B, on='date')\n",
    "# save\n",
    "df_national_results_B.to_csv(\"../results/national_forecast_B.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scenario C\n",
    "df_national_mean_vote_shares_C = calculate_mean_vote_share(provincial_forecast_C, dates_sc_C)\n",
    "df_national_win_probs_C = run_prob_simulation(provincial_forecast_C, dates_sc_C)\n",
    "df_national_results_C = df_national_mean_vote_shares_C.merge(df_national_win_probs_C, on='date')\n",
    "# save\n",
    "df_national_results_C.to_csv(\"../results/national_forecast_C.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scenario D\n",
    "df_national_mean_vote_shares_D = calculate_mean_vote_share(provincial_forecast_D, dates_sc_D)\n",
    "df_national_win_probs_D = run_prob_simulation(provincial_forecast_D, dates_sc_D)\n",
    "df_national_results_D = df_national_mean_vote_shares_D.merge(df_national_win_probs_D, on='date')\n",
    "# save\n",
    "df_national_results_D.to_csv(\"../results/national_forecast_D.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scenario E\n",
    "df_national_mean_vote_shares_E = calculate_mean_vote_share(provincial_forecast_E, dates_sc_E)\n",
    "df_national_win_probs_E = run_prob_simulation(provincial_forecast_E, dates_sc_E)\n",
    "df_national_results_E = df_national_mean_vote_shares_E.merge(df_national_win_probs_E, on='date')\n",
    "# save\n",
    "df_national_results_E.to_csv(\"../results/national_forecast_E.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b4d2ec6461578ecc325c1407f912d3ceeb97ba9431706f2445d02b7cc2e18252"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
